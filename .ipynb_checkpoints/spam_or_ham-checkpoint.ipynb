{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam or Ham: Basic Naive Bayes Email Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My aim in this project is use Bayes formula to construct a spam filter, which will predict based off of raw text whether a message is \"spam\" or \"ham (non-spam)\". The problem is one of binary classification in which my model will be appraised as accurate if it properly predicts the right label. The main accuracy metric, therefore, will be the number of correct labels divided by the number of overall guesses.  \n",
    "\n",
    "The dataset for this project is from the Data Science/Machine Learning competition website <a href=\"https://www.kaggle.com/uciml/sms-spam-collection-dataset\" target=\"#\">Kaggle</a>. The dataset is comprised of two columns, one for the message text and one for the label (\"ham\" or \"spam\"). There are 5169 rows of unique data."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "What is the probability (Pr) that a message is spam (S) given word (W)? This question is what <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering\" target=\"#\">Bayes' theorem</a> attempts to calculate. Divide the probability of a word being in a spam message by that same probability added to the probability of a word being in a ham message -- this is a simplified form of Bayes' theorem that excludes any prior assumptions regarding the probability of a message being ham or spam. To be more specific, in all of the spam messages, count the number of times a given word occurs and divide that by the number of overall words in the spam messages -- this constitutes the probability in the numerator. This probability is then added to the same calculation applied to the word's frequency in ham messages -- the denominator. \n",
    "\n",
    "Since each message contains multiple words, probabilities for each word given spam are multiplied, then the resulting product is divided by the same product added to the product of all the multiplied words given ham. The \"naive\" in Naive Bayes owes to the fact that multiplying probabilities together assumes a statistical independence these probabilities don't have -- and why's that? Because words aren't randomly assembled into sentences. Certain words occur frequently with others, but for the sake of simplicity, we're going to ignore this fact. Ignoring the patterns in language isn't foolhardy or \"naive\" in the pejorative sense, as model builders much more sophisticated than myself have proven time and again that Naive Bayes works really well for problems like spam filtering.\n",
    "\n",
    "While there are prebuilt Bayesian models provided by many popular Machine Learning libraries, for the sake of learning, I'll be building my own from scratch, only using libraries to preprocess and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read CSV file into a dataframe\n",
    "data = pd.read_csv(\"spam.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine top 5 rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the additional columns (Unnamed:2 through Unnamed: 4) have some text data,\n",
    "#but are primarily composed of null values and will be dropped.\n",
    "data = data[['v1','v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns for easier reference\n",
    "data.columns = ['msg_text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 in the dataframe after removing non-alphanumeric characters.\n"
     ]
    }
   ],
   "source": [
    "#create list of all the unique words that occur in the text col\n",
    "unique_words = []\n",
    "\n",
    "for i,row in data.iterrows():\n",
    "    for word in row['msg_text'].split(' '):\n",
    "        word = re.sub(r'\\W+', '', word)\n",
    "        if word in unique_words:\n",
    "            pass\n",
    "        else:\n",
    "            unique_words.append(word)\n",
    "            \n",
    "total_num_of_words = len(unique_words)\n",
    "\n",
    "print(\"There are {} in the dataframe after removing non-alphanumeric characters.\".format(total_num_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ham  spam\n",
       "0    1     0\n",
       "1    1     0\n",
       "2    0     1\n",
       "3    1     0\n",
       "4    1     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create empty dataframe to store word counts\n",
    "wordcount_df = pd.DataFrame(0, index=np.arange(len(data)), columns=unique_words)\n",
    "\n",
    "#count occurence of words in each message and increment the corresponding column\n",
    "for i, row in data.iterrows():\n",
    "    for word in row['msg_text'].split(' '):\n",
    "        word = re.sub(r'\\W+', '', word)\n",
    "        wordcount_df.iloc[i,unique_words.index(word)]+=1\n",
    "\n",
    "wordcount_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine word count dataframe with labels from original dataframe\n",
    "merged = pd.concat([wordcount_df,data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>msg_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ham  spam msg_text                                              label\n",
       "0    1     0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1    1     0      ham                      Ok lar... Joking wif u oni...\n",
       "2    0     1     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    1     0      ham  U dun say so early hor... U c already then say...\n",
       "4    1     0      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine first five rows of merged dataframe\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Class object to read in training dataset, calculate conditional probabilities\n",
    "#and create model to generate predictions for test dataset\n",
    "class PredictBayes:\n",
    "    def __init__(self):\n",
    "        self.priors = {}\n",
    "        self.conditionals = {}\n",
    "        self.predictions = []\n",
    "        self.prob_product = {}\n",
    "        \n",
    "    def fit(self,train,target):\n",
    "        self.target = target\n",
    "        self.train = train\n",
    "        self.labels = set(self.train[self.target].values)\n",
    "\n",
    "        for label in self.labels:\n",
    "            self.priors[label] = self.train[self.train[target]==label].shape[0]/self.train.shape[0]\n",
    "            data = self.train[self.train[self.target]==label]\n",
    "            self.conditionals[label] = data.drop(self.target,axis=1).sum()/data.drop(self.target,axis=1).sum().sum()\n",
    "            \n",
    "    def predict(self,test,features):\n",
    "        self.test = test\n",
    "        self.features = features\n",
    "        for label in self.labels:\n",
    "            product_list = []\n",
    "            for word in self.features.split(' '):\n",
    "                word = re.sub(r'\\W+', '', word)\n",
    "                product_list.append(self.conditionals[label][word])\n",
    "            self.prob_product[label] = product_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = PredictBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and test sets -- 80% and 20% of the data, respetively\n",
    "train, test = train_test_split(merged,test_size=.2,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.fit(train.drop('msg_text',axis=1),\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'msg_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4410\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4411\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4412\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-409d971f021d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"msg_text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-b69ff0f5b18b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test, features)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\W+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mproduct_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditionals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_product\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4417\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4418\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4419\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4420\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4421\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4403\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4406\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4407\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'msg_text'"
     ]
    }
   ],
   "source": [
    "testing.predict(test,\"msg_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
